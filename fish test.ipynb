{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd2e8c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "\n",
    "from __future__ import print_function\n",
    "print(__doc__)\n",
    "import operator\n",
    "from math import log\n",
    "from collections import Counter\n",
    "\n",
    "from matplotlib import pyplot as dtPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "080af981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    \"\"\"DateSet 基础数据集\n",
    "    Args:\n",
    "        无需传入参数\n",
    "    Returns:\n",
    "        返回数据集和对应的label标签\n",
    "    \"\"\"\n",
    "    dataSet = [(1, 1, 'yes'),\n",
    "               (1, 1, 'yes'),\n",
    "               (1, 0, 'no'),\n",
    "               (0, 1, 'no'),\n",
    "               (0, 1, 'no')]\n",
    "    # dataSet = [['yes'],\n",
    "    #         ['yes'],\n",
    "    #         ['no'],\n",
    "    #         ['no'],\n",
    "    #         ['no']]\n",
    "    # labels  露出水面   脚蹼\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    # change to discrete values\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25a659e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c86f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a66a4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1, 1, 'yes'), (1, 1, 'yes'), (1, 0, 'no'), (0, 1, 'no'), (0, 1, 'no')],\n",
       " ['no surfacing', 'flippers'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02cd4c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afeadf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(0, 1, 'no'): 1, 'flippers': 1})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data[-1] for data in d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81e595ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    label_count = Counter(tuple(data[-1]) for data in dataSet)\n",
    "    probs = [p[1] / len(dataSet) for p in label_count.items()]\n",
    "    shannonEnt = sum([-p * log(p, 2) for p in probs])\n",
    "    return shannonEnt\n",
    "\n",
    "\n",
    "\n",
    "def splitDataSet(dataSet, index, value):\n",
    "    \"\"\"splitDataSet(通过遍历dataSet数据集，求出index对应的colnum列的值为value的行)\n",
    "        就是依据index列进行分类，如果index列的数据等于 value的时候，就要将 index 划分到我们创建的新的数据集中\n",
    "    Args:\n",
    "        dataSet 数据集                 待划分的数据集\n",
    "        index 表示每一行的index列        划分数据集的特征\n",
    "        value 表示index列对应的value值   需要返回的特征的值。\n",
    "    Returns:\n",
    "        index列为value的数据集【该数据集需要排除index列】\n",
    "    \"\"\"\n",
    "    # -----------切分数据集的第一种方式 start------------------------------------\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet: \n",
    "        # index列为value的数据集【该数据集需要排除index列】\n",
    "        # 判断index列的值是否为value\n",
    "        if featVec[index] == value:\n",
    "            # chop out index used for splitting\n",
    "            # [:index]表示前index行，即若 index 为2，就是取 featVec 的前 index 行\n",
    "            reducedFeatVec = featVec[:index]\n",
    "            '''\n",
    "            请百度查询一下:  extend和append的区别\n",
    "            list.append(object) 向列表中添加一个对象object\n",
    "            list.extend(sequence) 把一个序列seq的内容添加到列表中\n",
    "            1、使用append的时候，是将new_media看作一个对象，整体打包添加到music_media对象中。\n",
    "            2、使用extend的时候，是将new_media看作一个序列，将这个序列和music_media序列合并，并放在其后面。\n",
    "            result = []\n",
    "            result.extend([1,2,3])\n",
    "            print result\n",
    "            result.append([4,5,6])\n",
    "            print result\n",
    "            result.extend([7,8,9])\n",
    "            print result\n",
    "            结果: \n",
    "            [1, 2, 3]\n",
    "            [1, 2, 3, [4, 5, 6]]\n",
    "            [1, 2, 3, [4, 5, 6], 7, 8, 9]\n",
    "            '''\n",
    "            reducedFeatVec.extend(featVec[index+1:])\n",
    "            # [index+1:]表示从跳过 index 的 index+1行，取接下来的数据\n",
    "            # 收集结果值 index列为value的行【该行需要排除index列】\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    # -----------切分数据集的第一种方式 end------------------------------------\n",
    "\n",
    "    # # -----------切分数据集的第二种方式 start------------------------------------\n",
    "    # retDataSet = [data for data in dataSet for i, v in enumerate(data) if i == axis and v == value]\n",
    "    # # -----------切分数据集的第二种方式 end------------------------------------\n",
    "    return retDataSet\n",
    "\n",
    "\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"chooseBestFeatureToSplit(选择最好的特征)\n",
    "    Args:\n",
    "        dataSet 数据集\n",
    "    Returns:\n",
    "        bestFeature 最优的特征列\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------选择最优特征的第一种方式 start------------------------------------\n",
    "    # 求第一行有多少列的 Feature, 最后一列是label列嘛\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    # label的信息熵\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    # 最优的信息增益值, 和最优的Featurn编号\n",
    "    bestInfoGain, bestFeature = 0.0, -1\n",
    "    # iterate over all the features\n",
    "    for i in range(numFeatures):\n",
    "        # create a list of all the examples of this feature\n",
    "        # 获取每一个实例的第i+1个feature，组成list集合\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        # get a set of unique values\n",
    "        # 获取剔重后的集合，使用set对list数据进行去重\n",
    "        uniqueVals = set(featList)\n",
    "        # 创建一个临时的信息熵\n",
    "        newEntropy = 0.0\n",
    "        # 遍历某一列的value集合，计算该列的信息熵 \n",
    "        # 遍历当前特征中的所有唯一属性值，对每个唯一属性值划分一次数据集，计算数据集的新熵值，并对所有唯一特征值得到的熵求和。\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        # gain[信息增益]: 划分数据集前后的信息变化， 获取信息熵最大的值\n",
    "        # 信息增益是熵的减少或者是数据无序度的减少。最后，比较所有特征中的信息增益，返回最好特征划分的索引值。\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        print('infoGain=', infoGain, 'bestFeature=', i, baseEntropy, newEntropy)\n",
    "        if (infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature\n",
    "    # -----------选择最优特征的第一种方式 end------------------------------------\n",
    "\n",
    "    # # -----------选择最优特征的第二种方式 start------------------------------------\n",
    "    # # 计算初始香农熵\n",
    "    # base_entropy = calcShannonEnt(dataSet)\n",
    "    # best_info_gain = 0\n",
    "    # best_feature = -1\n",
    "    # # 遍历每一个特征\n",
    "    # for i in range(len(dataSet[0]) - 1):\n",
    "    #     # 对当前特征进行统计\n",
    "    #     feature_count = Counter([data[i] for data in dataSet])\n",
    "    #     # 计算分割后的香农熵\n",
    "    #     new_entropy = sum(feature[1] / float(len(dataSet)) * calcShannonEnt(splitDataSet(dataSet, i, feature[0])) \\\n",
    "    #                    for feature in feature_count.items())\n",
    "    #     # 更新值\n",
    "    #     info_gain = base_entropy - new_entropy\n",
    "    #     print('No. {0} feature info gain is {1:.3f}'.format(i, info_gain))\n",
    "    #     if info_gain > best_info_gain:\n",
    "    #         best_info_gain = info_gain\n",
    "    #         best_feature = i\n",
    "    # return best_feature\n",
    "    # # -----------选择最优特征的第二种方式 end------------------------------------\n",
    "\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    \"\"\"majorityCnt(选择出现次数最多的一个结果)\n",
    "    Args:\n",
    "        classList label列的集合\n",
    "    Returns:\n",
    "        bestFeature 最优的特征列\n",
    "    \"\"\"\n",
    "    # -----------majorityCnt的第一种方式 start------------------------------------\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    # 倒叙排列classCount得到一个字典集合，然后取出第一个就是结果（yes/no），即出现次数最多的结果\n",
    "    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    # print 'sortedClassCount:', sortedClassCount\n",
    "    return sortedClassCount[0][0]\n",
    "    # -----------majorityCnt的第一种方式 end------------------------------------\n",
    "\n",
    "    # # -----------majorityCnt的第二种方式 start------------------------------------\n",
    "    # major_label = Counter(classList).most_common(1)[0]\n",
    "    # return major_label\n",
    "    # # -----------majorityCnt的第二种方式 end------------------------------------\n",
    "\n",
    "\n",
    "def createTree(dataSet, labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    # 如果数据集的最后一列的第一个值出现的次数=整个集合的数量，也就说只有一个类别，就只直接返回结果就行\n",
    "    # 第一个停止条件: 所有的类标签完全相同，则直接返回该类标签。\n",
    "    # count() 函数是统计括号中的值在list中出现的次数\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    # 如果数据集只有1列，那么最初出现label次数最多的一类，作为结果\n",
    "    # 第二个停止条件: 使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组。\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "\n",
    "    # 选择最优的列，得到最优列对应的label含义\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    # 获取label的名称\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    # 初始化myTree\n",
    "    myTree = {bestFeatLabel: {}}\n",
    "    # 注: labels列表是可变对象，在PYTHON函数中作为参数时传址引用，能够被全局修改\n",
    "    # 所以这行代码导致函数外的同名变量被删除了元素，造成例句无法执行，提示'no surfacing' is not in list\n",
    "    del(labels[bestFeat])\n",
    "    # 取出最优列，然后它的branch做分类\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        # 求出剩余的标签label\n",
    "        subLabels = labels[:]\n",
    "        # 遍历当前选择特征包含的所有属性值，在每个数据集划分上递归调用函数createTree()\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)\n",
    "        # print 'myTree', value, myTree\n",
    "    return myTree\n",
    "\n",
    "\n",
    "def classify(inputTree, featLabels, testVec):\n",
    "    \"\"\"classify(给输入的节点，进行分类)\n",
    "    Args:\n",
    "        inputTree  决策树模型\n",
    "        featLabels Feature标签对应的名称\n",
    "        testVec    测试输入的数据\n",
    "    Returns:\n",
    "        classLabel 分类的结果值，需要映射label才能知道名称\n",
    "    \"\"\"\n",
    "    # 获取tree的根节点对于的key值\n",
    "    firstStr = inputTree.keys()[0]\n",
    "    # 通过key得到根节点对应的value\n",
    "    secondDict = inputTree[firstStr]\n",
    "    # 判断根节点名称获取根节点在label中的先后顺序，这样就知道输入的testVec怎么开始对照树来做分类\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    # 测试数据，找到根节点对应的label位置，也就知道从输入的数据的第几位来开始分类\n",
    "    key = testVec[featIndex]\n",
    "    valueOfFeat = secondDict[key]\n",
    "    print('+++', firstStr, 'xxx', secondDict, '---', key, '>>>', valueOfFeat)\n",
    "    # 判断分枝是否结束: 判断valueOfFeat是否是dict类型\n",
    "    if isinstance(valueOfFeat, dict):\n",
    "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
    "    else:\n",
    "        classLabel = valueOfFeat\n",
    "    return classLabel\n",
    "\n",
    "\n",
    "def storeTree(inputTree, filename):\n",
    "    import pickle\n",
    "    # -------------- 第一种方法 start --------------\n",
    "    fw = open(filename, 'wb')\n",
    "    pickle.dump(inputTree, fw)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a620aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']],\n",
       " ['no surfacing', 'flippers'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5623e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEnt(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1deb0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
